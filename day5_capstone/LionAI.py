{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/venkatapotamsetti/capstone-lionai-py?scriptVersionId=281407363\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:20.189593Z","iopub.execute_input":"2025-11-23T17:28:20.190422Z","iopub.status.idle":"2025-11-23T17:28:20.195819Z","shell.execute_reply.started":"2025-11-23T17:28:20.190357Z","shell.execute_reply":"2025-11-23T17:28:20.194727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mermaid-py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:20.197403Z","iopub.execute_input":"2025-11-23T17:28:20.197659Z","iopub.status.idle":"2025-11-23T17:28:24.04387Z","shell.execute_reply.started":"2025-11-23T17:28:20.197641Z","shell.execute_reply":"2025-11-23T17:28:24.042673Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#f9f9f9; padding:15px; border-left:5px solid #4b8bbe; border-radius:6px;\">\n  <h1>ğŸ§  Agents Intensive â€“ Capstone Project</h1>\n  <h2>[CPD_Assistant â€” Multi-Agent Compliance & Training Manager for Healthcare]</h2>\n  <h3>Nickname: <em>â€œSmart CPD Agentâ€</em></h3>\n  <hr>\n  <p><strong>Course:</strong> Google Ã— Kaggle â€“ 5-Day AI Agents Intensive<br>\n     <strong>Competition:</strong> Agents Intensive â€“ Capstone Project</p>\n  <p><strong>Team:</strong><br>\n     â€¢ Venkat Potamsetti â€“ London (UTC+0)<br>\n     â€¢ Kamran Shirazi â€“ San Diego (UTC-8)<br>\n     â€¢ Gita Mukesh â€“ Dubai (UTC+4)</p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#f4faff; padding:15px; border-left:5px solid #2a9df4; border-radius:6px; font-family:sans-serif;\">\n  <h3>ğŸ“Œ 1. Problem Overview</h3>\n\n  <p><strong>Real-world context:</strong><br>\n  Professional development tracking in regulated sectors (e.g., healthcare, finance, legal) where individuals must meet Continuing Professional Development (CPD) requirements to maintain certifications and licenses.</p>\n\n  <p><strong>Core user pain point:</strong><br>\n  Manual CPD tracking is fragmented across spreadsheets, LMS exports, and email recordsâ€”making it error-prone, time-consuming, and stressful during audits or revalidation cycles.</p>\n\n  <p><strong>Who is the primary user? (persona):</strong><br>\n  <ul>\n    <li><strong>Name:</strong> Priya â€“ Compliance Manager at a mid-sized healthcare LLP</li>\n    <li><strong>Goals:</strong> Ensure all staff meet CPD thresholds, maintain audit-ready records, and reduce admin overhead</li>\n    <li><strong>Constraints:</strong> Limited visibility across systems, high regulatory burden, no unified dashboard</li>\n  </ul>\n  </p>\n\n  <p><strong>One-sentence value proposition:</strong><br>\n  <em>â€œOur agent helps Priya ensure CPD compliance across her team by automating tracking, flagging gaps, and generating audit-ready reports.â€</em></p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#eef6fb; padding:15px; border-left:5px solid #0077b6; border-radius:6px; font-family:sans-serif;\">\n  <h3>âš™ï¸ 2. Capabilities & Requirements</h3>\n\n  <p><strong>Agent type:</strong><br>\n  Multi-agent system with modular specialization:</p>\n  <ul>\n    <li><code>orchestrator.py</code>: Delegates tasks and manages agent interactions</li>\n    <li><code>requirements_agent.py</code>: Maps staff roles to required CPD modules</li>\n    <li><code>monitoring_agent.py</code>: Calculates compliance KPIs and flags gaps</li>\n    <li><code>reminder_agent.py</code>: Generates personalized CPD reminders</li>\n    <li><code>reporting_agent.py</code>: Builds dashboards and audit-ready reports</li>\n  </ul>\n\n  <p><strong>Key capabilities (required by capstone):</strong></p>\n  <ul>\n    <li>[x] Uses Gemini for reasoning / generation</li>\n    <li>[x] Uses at least one tool / MCP integration:\n      <ul>\n        <li><code>file_reader.py</code> for parsing CPD records (CSV, Excel, PDF)</li>\n        <li><code>hr_data.py</code> for staff and training metadata</li>\n        <li><code>notification.py</code> for templated alerts</li>\n        <li><code>storage.py</code> for persistent audit logs</li>\n      </ul>\n    </li>\n    <li>[x] Uses at least <strong>3 GenAI features</strong>:\n      <ul>\n        <li>Structured output (JSON logs, role-module mappings)</li>\n        <li>Function calling (KPI thresholds, alert triggers)</li>\n        <li>Tool use (file parsing, HR data ingestion, notification generation)</li>\n      </ul>\n    </li>\n    <li>[x] Has a basic <strong>evaluation plan</strong>:\n      <ul>\n        <li>Unit tests for mapping, KPI accuracy, and edge cases</li>\n        <li>Evaluation notebook with precision/recall metrics</li>\n        <li>User feedback from demo notebook</li>\n      </ul>\n    </li>\n    <li>[x] Includes explanation of <strong>safety / guardrails / failure modes</strong>:\n      <ul>\n        <li>Guardrails: Role-based access, schema validation, audit log immutability</li>\n        <li>Failure modes: Incomplete data ingestion, outdated role mappings, false positives in alerts</li>\n      </ul>\n    </li>\n  </ul>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#e8f5e9; padding:15px; border-left:5px solid #43a047; border-radius:6px; font-family:sans-serif;\">\n  <h3>ğŸ—ºï¸ 3. Notebook Roadmap</h3>\n\n  <ol>\n    <li><strong>Setup & configuration</strong><br>\n        Install dependencies, load sample data, and initialize agent modules.</li>\n    <li><strong>Problem & user requirements</strong><br>\n        Define real-world context, user pain points, and compliance goals.</li>\n    <li><strong>Agent architecture & design</strong><br>\n        Outline multi-agent structure and responsibilities.</li>\n    <li><strong>Tooling / MCP integration</strong><br>\n        Demonstrate use of tools and schema interoperability.</li>\n    <li><strong>Core agent loop (demo runs)</strong><br>\n        Simulate CPD ingestion, compliance checks, alert generation, and dashboard output.</li>\n    <li><strong>Evaluation & metrics</strong><br>\n        Present precision/recall, audit log completeness, and user feedback.</li>\n    <li><strong>Limitations, risks & future work</strong><br>\n        Discuss edge cases, failure modes, and roadmap for scaling or regulatory updates.</li>\n    <li><strong>Appendix: configs, prompts, environment info</strong><br>\n        Include sample configs, prompt templates, environment setup, and test coverage summary.</li>\n  </ol>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## ğŸ§  CPD_Assistant â€“ Setup & Configuration Workflow\n\n          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n          â”‚  ğŸ”§ Environment Setup     â”‚\n          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                       â†“\n          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n          â”‚  ğŸ“¦ Install Dependencies  â”‚\n          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                       â†“\n          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n          â”‚  ğŸ“ Load Sample Data      â”‚\n          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                       â†“\n          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n          â”‚  ğŸ¤– Initialise Agents     â”‚\n          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n               â†“        â†“        â†“\n     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n     â”‚ âœ… Agent Registry â”‚ â”‚ ğŸ“Š Data Ingestion     â”‚ â”‚ ğŸš€ Ready for Demo & Eval â”‚\n     â”‚    Confirmation   â”‚ â”‚     Summary         â”‚ â”‚     Loop & Launch        â”‚\n     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#fff3e0; padding:15px; border-left:5px solid #fb8c00; border-radius:6px; font-family:sans-serif;\">\n  <h3>ğŸ› ï¸ Section 1. Setup & Configuration</h3>\n    \nThis section prepares the CPD_Assistant environment by:\n\n1.1. Installing dependencies\n1.2. Loading mock data\n1.3. Initialising agent and tool modules","metadata":{}},{"cell_type":"markdown","source":"### âœ… Step 1.1: Install Dependencies","metadata":{}},{"cell_type":"code","source":"import pandas, numpy, matplotlib, sklearn, tqdm\nprint(\"âœ… Core packages are available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.04601Z","iopub.execute_input":"2025-11-23T17:28:24.04634Z","iopub.status.idle":"2025-11-23T17:28:24.051833Z","shell.execute_reply.started":"2025-11-23T17:28:24.046309Z","shell.execute_reply":"2025-11-23T17:28:24.051016Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Configure Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/), which requires an API key.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to access the `GOOGLE_API_KEY` you just saved and set it as an environment variable for the notebook to use:","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"ğŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.052784Z","iopub.execute_input":"2025-11-23T17:28:24.05307Z","iopub.status.idle":"2025-11-23T17:28:24.431786Z","shell.execute_reply.started":"2025-11-23T17:28:24.053041Z","shell.execute_reply":"2025-11-23T17:28:24.430812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"import json\nimport requests\nimport subprocess\nimport time\nimport uuid\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.remote_a2a_agent import (\n    RemoteA2aAgent,\n    AGENT_CARD_WELL_KNOWN_PATH,\n)\n\nfrom google.adk.a2a.utils.agent_to_a2a import to_a2a\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# Hide additional warnings in the notebook\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"âœ… ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.433911Z","iopub.execute_input":"2025-11-23T17:28:24.434181Z","iopub.status.idle":"2025-11-23T17:28:24.441499Z","shell.execute_reply.started":"2025-11-23T17:28:24.43416Z","shell.execute_reply":"2025-11-23T17:28:24.440431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, field\nimport json\nimport sklearn, tqdm\n\nprint(\"âœ… Python core packages imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T11:02:16.449594Z","iopub.execute_input":"2025-11-24T11:02:16.449922Z","iopub.status.idle":"2025-11-24T11:02:16.456227Z","shell.execute_reply.started":"2025-11-24T11:02:16.449901Z","shell.execute_reply":"2025-11-24T11:02:16.455278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### âœ… Step 1.2. Loading mock data ","metadata":{}},{"cell_type":"code","source":"# === Synthetic CPD data for the CPD_Assistant agents ===\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\n\nnp.random.seed(42)\n\ndepartments = [\"Inpatients\", \"Outpatients\", \"Community\", \"Admin\"]\nroles = [\"Nurse\", \"Support Worker\", \"Physiotherapist\", \"Admin\", \"Manager\"]\n\nn_staff = 50\nstaff_ids = list(range(1, n_staff + 1))\n\nbase_date = pd.Timestamp.today().normalize()\n\n# Staff dataset: one row per staff member\nstaff_df = pd.DataFrame({\n    \"staff_id\": staff_ids,\n    \"staff_name\": [f\"Staff_{i:02d}\" for i in staff_ids],\n    \"department\": np.random.choice(departments, size=n_staff),\n    \"role\": np.random.choice(roles, size=n_staff),\n    \"hire_date\": base_date - pd.to_timedelta(\n        np.random.randint(30, 365 * 5, size=n_staff), unit=\"D\"\n    ),\n})\n\n# Training modules dataset\nmodules = [\n    \"Safeguarding\",\n    \"Data Protection\",\n    \"Basic Life Support\",\n    \"Fire Safety\",\n    \"Manual Handling\",\n]\n\nmodules_df = pd.DataFrame({\n    \"module_id\": range(1, len(modules) + 1),\n    \"module_name\": modules,\n    \"validity_days\": [365, 365, 365, 365, 730],\n})\n\n# Completions dataset: multiple rows per staff (one per module)\nrecords = []\ntoday = pd.Timestamp.today().normalize().date()\n\nfor sid in staff_ids:\n    for _, m in modules_df.iterrows():\n        due_date = today + timedelta(days=np.random.randint(-90, 90))\n\n        # Simple logic to generate status\n        if due_date < today and np.random.rand() < 0.5:\n            status = \"Overdue\"\n            completion_date = None\n        elif np.random.rand() < 0.7:\n            status = \"Completed\"\n            completion_date = due_date - timedelta(days=np.random.randint(0, 60))\n        else:\n            status = \"Pending\"\n            completion_date = None\n\n        records.append({\n            \"staff_id\": sid,\n            \"module_id\": m[\"module_id\"],\n            \"status\": status,\n            \"due_date\": due_date,\n            \"completion_date\": completion_date,\n        })\n\ncompletions_df = pd.DataFrame(records)\n\n# Optional: save so later cells can read from disk (matches your paths)\nstaff_df.to_csv(\"/kaggle/working/sample_staff.csv\", index=False)\nmodules_df.to_csv(\"/kaggle/working/training_modules.csv\", index=False)\ncompletions_df.to_csv(\"/kaggle/working/completions.csv\", index=False)\n\nprint(\"âœ… Synthetic CPD data created:\")\nprint(\"staff_df:\", staff_df.shape)\nprint(\"modules_df:\", modules_df.shape)\nprint(\"completions_df:\", completions_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.463109Z","iopub.execute_input":"2025-11-23T17:28:24.463446Z","iopub.status.idle":"2025-11-23T17:28:24.50756Z","shell.execute_reply.started":"2025-11-23T17:28:24.463417Z","shell.execute_reply":"2025-11-23T17:28:24.506632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### d. Role Mappings (JSON)","metadata":{}},{"cell_type":"code","source":"import json\n\n# Role to Module Mapping\nrole_mappings = {\n    'Manager': [1, 3, 5],  # Modules assigned to Managers\n    'Developer': [2, 4],\n    'HR': [1, 2],\n    'Analyst': [3, 4],\n    'Support': [1, 2, 3]\n}\n\nwith open('/kaggle/working/role_mappings.json', 'w') as f:\n    json.dump(role_mappings, f, indent=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.508584Z","iopub.execute_input":"2025-11-23T17:28:24.50891Z","iopub.status.idle":"2025-11-23T17:28:24.51493Z","shell.execute_reply.started":"2025-11-23T17:28:24.508887Z","shell.execute_reply":"2025-11-23T17:28:24.514167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### e. Read and Test Datasets:","metadata":{}},{"cell_type":"code","source":"staff_df = pd.read_csv('/kaggle/working/sample_staff.csv')\nmodules_df = pd.read_csv('/kaggle/working/training_modules.csv')\ncompletions_df = pd.read_csv('/kaggle/working/completions.csv')\n\nprint ('success')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.515767Z","iopub.execute_input":"2025-11-23T17:28:24.515986Z","iopub.status.idle":"2025-11-23T17:28:24.535956Z","shell.execute_reply.started":"2025-11-23T17:28:24.515968Z","shell.execute_reply":"2025-11-23T17:28:24.535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### âœ… Step 1.3. Initialising agent and tool modules","metadata":{}},{"cell_type":"markdown","source":"### ğŸ¤– Agent Base Class","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nfrom typing import List, Dict, Any, Optional\n\nclass Agent:\n    def __init__(self, name: str):\n        self.name = name\n        self.audit_log: List[Dict[str, Any]] = []\n\n    def log_action(self, action: str, details: Optional[Dict[str, Any]] = None):\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"agent\": self.name,\n            \"action\": action,\n            \"details\": details or {},\n        }\n        self.audit_log.append(entry)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.536871Z","iopub.execute_input":"2025-11-23T17:28:24.537333Z","iopub.status.idle":"2025-11-23T17:28:24.544569Z","shell.execute_reply.started":"2025-11-23T17:28:24.537296Z","shell.execute_reply":"2025-11-23T17:28:24.543501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¤– HR Data Agent","metadata":{}},{"cell_type":"code","source":"class HRDataAgent(Agent):\n    \"\"\"Handles all data retrieval operations.\"\"\"\n    \n    def __init__(\n        self,\n        staff_df: pd.DataFrame,\n        modules_df: pd.DataFrame,\n        completions_df: pd.DataFrame\n    ):\n        super().__init__(\"HR_Data_Agent\")\n\n        self.staff_df = staff_df\n        self.modules_df = modules_df\n\n        # Convert date columns to datetime safely\n        self.completions_df = completions_df.copy()\n        self.completions_df[\"due_date\"] = pd.to_datetime(\n            self.completions_df[\"due_date\"], errors=\"coerce\"\n        )\n\n        if \"completion_date\" in self.completions_df.columns:\n            self.completions_df[\"completion_date\"] = pd.to_datetime(\n                self.completions_df[\"completion_date\"], errors=\"coerce\"\n            )\n        \n        # Cache for merged data\n        self._merged_cache = None\n\n        self.log_action(\"initialized\", {\"message\": \"HR Data Agent ready\"})\n\n    # ---------------------------------------------------------\n    def _merged(self) -> pd.DataFrame:\n        \"\"\"Internal helper to merge staff, modules, and completion records.\"\"\"\n        if self._merged_cache is None:\n            merged = (\n                self.completions_df\n                .merge(self.staff_df, on=\"staff_id\", how=\"left\")\n                .merge(self.modules_df, on=\"module_id\", how=\"left\")\n            )\n            self._merged_cache = merged\n\n        return self._merged_cache.copy()\n\n    # ---------------------------------------------------------\n    def get_staff_training_status(self, staff_id=None) -> pd.DataFrame:\n        \"\"\"Get training completion status for all staff or a specific staff member.\"\"\"\n        \n        self.log_action(\n            \"get_staff_training_status\",\n            {\"staff_id\": staff_id if staff_id is not None else \"all\"}\n        )\n        \n        df = self._merged()\n        if staff_id is not None:\n            df = df[df[\"staff_id\"] == staff_id]\n        return df\n\n    # ---------------------------------------------------------\n    def get_pending_training(self, module_name=None) -> pd.DataFrame:\n        \"\"\"Return all pending or overdue training records.\"\"\"\n        \n        self.log_action(\n            \"get_pending_training\",\n            {\"module\": module_name or \"all\"}\n        )\n\n        df = self._merged()\n        df = df[df[\"status\"].isin([\"Pending\", \"Overdue\"])]\n\n        if module_name:\n            df = df[df[\"module_name\"].str.lower() == module_name.lower()]\n\n        return df\n\n    # ---------------------------------------------------------\n    def get_overdue_training(self) -> pd.DataFrame:\n        \"\"\"Return records where training is overdue based on due_date.\"\"\"\n        \n        self.log_action(\"get_overdue_training\", {\"message\": \"Fetching overdue records\"})\n        \n        df = self._merged()\n        today = pd.Timestamp.today().normalize()\n\n        # Ensure due_date is datetime\n        df[\"due_date\"] = pd.to_datetime(df[\"due_date\"], errors=\"coerce\")\n\n        mask = (\n            (df[\"status\"] == \"Overdue\") |\n            ((df[\"status\"] == \"Pending\") & (df[\"due_date\"] < today))\n        )\n\n        return df[mask]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.545644Z","iopub.execute_input":"2025-11-23T17:28:24.54601Z","iopub.status.idle":"2025-11-23T17:28:24.564297Z","shell.execute_reply.started":"2025-11-23T17:28:24.545986Z","shell.execute_reply":"2025-11-23T17:28:24.563285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¤– Monitoring Agent","metadata":{}},{"cell_type":"code","source":"class MonitoringAgent(Agent):\n    \"\"\"Handles KPI calculations and performance tracking\"\"\"\n    \n    def __init__(self, hr_agent: HRDataAgent):\n        super().__init__(\"Monitoring_Agent\")\n        self.hr_agent = hr_agent\n        self.log_action(\"initialized\", {\"message\": \"Monitoring Agent ready\"})\n    \n    def calculate_completion_rate(self, department: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Calculate training completion rate\"\"\"\n        self.log_action(\"calculate_completion_rate\", {\"department\": department})\n        \n        df = self.hr_agent.get_staff_training_status()\n        if department:\n            df = df[df[\"department\"] == department]\n        \n        total = len(df)\n        completed = (df[\"status\"] == \"Completed\").sum()\n        rate = (completed / total * 100) if total else 0.0\n        \n        return {\n            \"total_training_records\": int(total),\n            \"completed\": int(completed),\n            \"pending\": int(total - completed),\n            \"completion_rate\": round(rate, 2),\n            \"department\": department or \"all\",\n        }\n\n    def get_module_statistics(self) -> pd.DataFrame:\n        \"\"\"Aggregate completion stats per module.\"\"\"\n        self.log_action(\"get_module_statistics\", {\"message\": \"Aggregating module stats\"})\n        df = self.hr_agent.get_staff_training_status()\n        g = df.groupby(\"module_name\")[\"status\"].value_counts().unstack(fill_value=0)\n        \n        total = g.sum(axis=1)\n        completed = g.get(\"Completed\", 0)\n        pending = total - completed\n        completion_rate = (completed / total * 100).round(2)\n        \n        stats = pd.DataFrame({\n            \"module_name\": g.index,\n            \"completed\": completed.values,\n            \"pending\": pending.values,\n            \"completion_rate\": completion_rate.values,\n        })\n        return stats\n\n    def identify_underperformers(self, threshold: float = 70.0) -> pd.DataFrame:\n        \"\"\"Identify staff whose overall completion rate is below the threshold.\"\"\"\n        self.log_action(\"identify_underperformers\", {\"threshold\": threshold})\n        df = self.hr_agent.get_staff_training_status()\n        \n        total_per_staff = df.groupby([\"staff_id\", \"staff_name\"])[\"status\"].count()\n        completed_per_staff = (\n            df[df[\"status\"] == \"Completed\"]\n            .groupby([\"staff_id\", \"staff_name\"])[\"status\"]\n            .count()\n        )\n        completion_rate = (completed_per_staff / total_per_staff * 100).fillna(0)\n        \n        result = completion_rate.reset_index(name=\"completion_rate\")\n        result = result[result[\"completion_rate\"] < threshold]\n        return result.sort_values(\"completion_rate\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.565278Z","iopub.execute_input":"2025-11-23T17:28:24.565561Z","iopub.status.idle":"2025-11-23T17:28:24.579929Z","shell.execute_reply.started":"2025-11-23T17:28:24.565541Z","shell.execute_reply":"2025-11-23T17:28:24.578941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¤– Reporting Agent","metadata":{}},{"cell_type":"code","source":"class ReportingAgent(Agent):\n    \"\"\"Generates visual reports and analytics\"\"\"\n    \n    def __init__(self, monitoring_agent: MonitoringAgent):\n        super().__init__(\"Reporting_Agent\")\n        self.monitoring_agent = monitoring_agent\n        self.log_action(\"initialized\", {\"message\": \"Reporting Agent ready\"})\n    \n    def generate_completion_dashboard(self, figsize=(14, 9)):\n        \"\"\"\n        Generate a clear, 2x2 KPI dashboard:\n        - Overall completion pie\n        - Completion rate by module (bar)\n        - Completed vs pending by module (grouped bar)\n        - Top underperformers (horizontal bar)\n        \"\"\"\n        self.log_action(\"generate_completion_dashboard\", {\"message\": \"Creating dashboard\"})\n        \n        # Create figure and a flat list of axes for easier handling\n        fig, axes = plt.subplots(2, 2, figsize=figsize)\n        axes = axes.flatten()\n        fig.suptitle(\"Training Completion Dashboard\", fontsize=16, fontweight=\"bold\")\n        \n        # ---------------------------------------------------------------------\n        # 1) Overall completion rate (pie)\n        # ---------------------------------------------------------------------\n        overall = self.monitoring_agent.calculate_completion_rate()\n        ax1 = axes[0]\n        \n        completed = overall.get(\"completed\", 0)\n        pending = overall.get(\"pending\", 0)\n        total = completed + pending\n        \n        if total == 0:\n            ax1.text(\n                0.5, 0.5,\n                \"No training records found\",\n                ha=\"center\", va=\"center\", fontsize=12\n            )\n            ax1.set_title(\"Overall Completion Rate\")\n        else:\n            ax1.pie(\n                [completed, pending],\n                labels=[\"Completed\", \"Pending\"],\n                autopct=\"%1.1f%%\",\n                startangle=90\n            )\n            ax1.set_title(f\"Overall Completion Rate: {overall['completion_rate']}%\")\n        \n        # ---------------------------------------------------------------------\n        # 2) Module completion rate (bar)\n        # ---------------------------------------------------------------------\n        module_stats = self.monitoring_agent.get_module_statistics()\n        ax2 = axes[1]\n        \n        if module_stats.empty:\n            ax2.text(\n                0.5, 0.5,\n                \"No module statistics available\",\n                ha=\"center\", va=\"center\", fontsize=12\n            )\n            ax2.set_title(\"Completion Rate by Module\")\n        else:\n            ax2.bar(\n                module_stats[\"module_name\"],\n                module_stats[\"completion_rate\"]\n            )\n            ax2.set_ylabel(\"Completion Rate (%)\")\n            ax2.set_title(\"Completion Rate by Module\")\n            ax2.set_ylim(0, 100)\n            ax2.set_xticklabels(\n                module_stats[\"module_name\"],\n                rotation=30,\n                ha=\"right\"\n            )\n            ax2.grid(axis=\"y\", alpha=0.3)\n        \n        # ---------------------------------------------------------------------\n        # 3) Completed vs Pending by module (grouped bar)\n        # ---------------------------------------------------------------------\n        ax3 = axes[2]\n        if module_stats.empty:\n            ax3.text(\n                0.5, 0.5,\n                \"No module statistics available\",\n                ha=\"center\", va=\"center\", fontsize=12\n            )\n            ax3.set_title(\"Completed vs Pending by Module\")\n        else:\n            x = np.arange(len(module_stats))\n            width = 0.35\n            \n            ax3.bar(x - width/2, module_stats[\"completed\"], width, label=\"Completed\")\n            ax3.bar(x + width/2, module_stats[\"pending\"],   width, label=\"Pending\")\n            \n            ax3.set_xticks(x)\n            ax3.set_xticklabels(\n                module_stats[\"module_name\"],\n                rotation=30,\n                ha=\"right\"\n            )\n            ax3.set_ylabel(\"Number of Records\")\n            ax3.set_title(\"Completed vs Pending by Module\")\n            ax3.legend()\n            ax3.grid(axis=\"y\", alpha=0.3)\n        \n        # ---------------------------------------------------------------------\n        # 4) Underperformers (horizontal bar)\n        # ---------------------------------------------------------------------\n        underperformers = self.monitoring_agent.identify_underperformers()\n        ax4 = axes[3]\n        \n        if underperformers.empty:\n            ax4.text(\n                0.5, 0.5,\n                \"No underperformers found\",\n                ha=\"center\", va=\"center\", fontsize=12\n            )\n            ax4.set_title(\"Underperformers\")\n        else:\n            top_underperformers = underperformers.head(10)\n            ax4.barh(\n                top_underperformers[\"staff_name\"],\n                top_underperformers[\"completion_rate\"]\n            )\n            ax4.set_xlabel(\"Completion Rate (%)\")\n            ax4.set_title(\"Top 10 Underperformers\")\n            ax4.set_xlim(0, 100)\n            ax4.invert_yaxis()  # highest at the top\n        \n        # ---------------------------------------------------------------------\n        # Layout\n        # ---------------------------------------------------------------------\n        fig.tight_layout(rect=[0, 0, 1, 0.95])\n        return fig\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.583013Z","iopub.execute_input":"2025-11-23T17:28:24.583622Z","iopub.status.idle":"2025-11-23T17:28:24.60222Z","shell.execute_reply.started":"2025-11-23T17:28:24.583588Z","shell.execute_reply":"2025-11-23T17:28:24.601244Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¤– Reminder Agent","metadata":{}},{"cell_type":"code","source":"class ReminderAgent(Agent):\n    \"\"\"Generates reminders and notifications\"\"\"\n    \n    def __init__(self, hr_agent:HRDataAgent):\n        super().__init__(\"Reminder_Agent\")\n        self.hr_agent = hr_agent\n        self.log_action(\"initialized\", {\"message\": \"Reminder Agent ready\"})\n    \n    def generate_reminder_email(self, staff_id: int) -> str:\n        \"\"\"Generate reminder email for a staff member\"\"\"\n        self.log_action(\"generate_reminder_email\", {\"staff_id\": staff_id})\n        \n        pending = self.hr_agent.get_pending_training()\n        staff_pending = pending[pending[\"staff_id\"] == staff_id]\n        \n        if staff_pending.empty:\n            return f\"No pending training found for staff_id={staff_id}.\"\n        \n        staff_name = staff_pending[\"staff_name\"].iloc[0]\n        lines = []\n        for _, row in staff_pending.sort_values(\"due_date\").iterrows():\n            due_str = row[\"due_date\"].strftime(\"%Y-%m-%d\")\n            lines.append(f\"- {row['module_name']} (due {due_str})\")\n        \n        email = f\"\"\"Dear {staff_name},\n\nOur records show that you have the following mandatory training outstanding:\n\n{chr(10).join(lines)}\n\nPlease log into the learning system and complete these modules as soon as possible.\n\nMany thanks,\nCPD Assistant\n\"\"\"\n        return email\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.603097Z","iopub.execute_input":"2025-11-23T17:28:24.603311Z","iopub.status.idle":"2025-11-23T17:28:24.623817Z","shell.execute_reply.started":"2025-11-23T17:28:24.603295Z","shell.execute_reply":"2025-11-23T17:28:24.622899Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ¤– Orchestrator Agent","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nimport json\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass OrchestratorAgent:\n    def __init__(self, hr_agent, monitoring_agent, reporting_agent, reminder_agent):\n        \"\"\"Initialize orchestrator with already-created agent instances\"\"\"\n        self.hr_agent = hr_agent\n        self.monitoring_agent = monitoring_agent\n        self.reporting_agent = reporting_agent\n        self.reminder_agent = reminder_agent\n        self.audit_log = []\n        self.log_action(\"initialized\", {\"message\": \"Orchestrator ready\"})\n    \n    def log_action(self, action: str, details: dict = None):\n        \"\"\"Log orchestrator actions\"\"\"\n        entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"agent\": \"Orchestrator\",\n            \"action\": action,\n            \"details\": details or {},\n        }\n        self.audit_log.append(entry)\n    \n    def process_query(self, query: str):\n        \"\"\"Route queries to appropriate agents based on content\"\"\"\n        query_lower = query.lower()\n        \n        if \"completion rate\" in query_lower or \"training completion\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"completion_rate\", \"query\": query})\n            return self.monitoring_agent.calculate_completion_rate()\n        \n        elif \"safeguarding\" in query_lower and \"pending\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"pending_safeguarding\", \"query\": query})\n            pending = self.hr_agent.get_pending_training(module_name=\"Safeguarding\")\n            return pending\n        \n        elif \"falling behind\" in query_lower or \"underperform\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"underperformers\", \"query\": query})\n            return self.monitoring_agent.identify_underperformers()\n        \n        elif \"dashboard\" in query_lower or \"kpi\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"dashboard\", \"query\": query})\n            return self.reporting_agent.generate_completion_dashboard()\n        \n        elif \"overdue\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"overdue\", \"query\": query})\n            return self.hr_agent.get_overdue_training()\n        \n        elif \"reminder\" in query_lower or \"email\" in query_lower:\n            self.log_action(\"process_query\", {\"type\": \"reminder\", \"query\": query})\n            import re\n            match = re.search(r'staff[_\\s]*id[:\\s]*(\\d+)', query_lower)\n            if match:\n                staff_id = int(match.group(1))\n                return self.reminder_agent.generate_reminder_email(staff_id)\n            else:\n                return {\"error\": \"Please specify a staff_id for reminder generation\"}\n        \n        else:\n            self.log_action(\"process_query\", {\"type\": \"unrecognized\", \"query\": query})\n            return {\n                \"error\": \"Query not recognized. Try asking about: completion rates, \"\n                \"pending training, underperformers, dashboards, or reminders.\"\n            }\n    \n    def get_all_audit_logs(self):\n        \"\"\"Return a dict of audit logs for orchestrator and all child agents\"\"\"\n        logs = {\n            \"orchestrator\": self.audit_log,\n            \"hr_agent\": self.hr_agent.audit_log,\n            \"monitoring_agent\": self.monitoring_agent.audit_log,\n            \"reporting_agent\": self.reporting_agent.audit_log,\n            \"reminder_agent\": self.reminder_agent.audit_log,\n        }\n        return logs\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.624777Z","iopub.execute_input":"2025-11-23T17:28:24.625043Z","iopub.status.idle":"2025-11-23T17:28:24.647727Z","shell.execute_reply.started":"2025-11-23T17:28:24.625024Z","shell.execute_reply":"2025-11-23T17:28:24.64676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Intallisation Function ","metadata":{}},{"cell_type":"code","source":"# === FIX: Add this cell BEFORE initializing agents ===\n\nimport pandas as pd\n\n# Reload data with proper date parsing\nstaff_df = pd.read_csv('/kaggle/working/sample_staff.csv')\nmodules_df = pd.read_csv('/kaggle/working/training_modules.csv')\ncompletions_df = pd.read_csv('/kaggle/working/completions.csv')\n\n# Convert date columns to datetime\ncompletions_df['due_date'] = pd.to_datetime(completions_df['due_date'])\nif 'completion_date' in completions_df.columns:\n    completions_df['completion_date'] = pd.to_datetime(completions_df['completion_date'], errors='coerce')\n\nprint(\"âœ… Data loaded with proper date parsing\")\nprint(f\"due_date dtype: {completions_df['due_date'].dtype}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.648697Z","iopub.execute_input":"2025-11-23T17:28:24.649056Z","iopub.status.idle":"2025-11-23T17:28:24.678309Z","shell.execute_reply.started":"2025-11-23T17:28:24.649025Z","shell.execute_reply":"2025-11-23T17:28:24.677261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def initialize_agents(staff_df, modules_df, completions_df):\n    \"\"\"Initialize all agents and return the orchestrator\"\"\"\n    \n    print(\"=\" * 60)\n    print(\"INITIALIZING MULTI-AGENT TRAINING MANAGEMENT SYSTEM\")\n    print(\"=\" * 60)\n    \n    print(\"\\n1. Initializing HR Data Agent...\")\n    hr_agent = HRDataAgent(staff_df, modules_df, completions_df)\n    \n    print(\"2. Initializing Monitoring Agent...\")\n    monitoring_agent = MonitoringAgent(hr_agent)\n    \n    print(\"3. Initializing Reporting Agent...\")\n    reporting_agent = ReportingAgent(monitoring_agent)\n    \n    print(\"4. Initializing Reminder Agent...\")\n    reminder_agent = ReminderAgent(hr_agent)\n    \n    print(\"5. Initializing Orchestrator Agent...\")\n    orchestrator = OrchestratorAgent(\n        hr_agent=hr_agent,\n        monitoring_agent=monitoring_agent,\n        reporting_agent=reporting_agent,\n        reminder_agent=reminder_agent\n    )\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"ALL AGENTS INITIALIZED SUCCESSFULLY\")\n    print(\"=\" * 60)\n    \n    return orchestrator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.679884Z","iopub.execute_input":"2025-11-23T17:28:24.680201Z","iopub.status.idle":"2025-11-23T17:28:24.688701Z","shell.execute_reply.started":"2025-11-23T17:28:24.680181Z","shell.execute_reply":"2025-11-23T17:28:24.687882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Usage Example","metadata":{}},{"cell_type":"code","source":"# Usage example\nif __name__ == \"__main__\":\n    # Load your data\n    staff_df = pd.read_csv('/kaggle/working/sample_staff.csv')\n    modules_df = pd.read_csv('/kaggle/working/training_modules.csv')\n    completions_df = pd.read_csv('/kaggle/working/completions.csv')\n    \n    # Initialize the agent system\n    orchestrator = initialize_agents(staff_df, modules_df, completions_df)\n    \n    # Example queries from team lead\n    print(\"\\n\" + \"=\" * 60)\n    print(\"DEMO: TEAM LEAD QUERIES\")\n    print(\"=\" * 60)\n    \n    # Query 1: Completion rate\n    print(\"\\n[Team Lead] What's the overall training completion rate?\")\n    result = orchestrator.process_query(\"What's the overall training completion rate?\")\n    print(json.dumps(result, indent=2, default=str))\n    \n    # Query 2: Pending safeguarding training\n    print(\"\\n[Team Lead] How many staff are due to complete safeguarding training?\")\n    result = orchestrator.process_query(\"How many staff are pending safeguarding training?\")\n    if isinstance(result, pd.DataFrame):\n        print(f\"\\nFound {len(result)} staff members with pending Safeguarding training\")\n        if not result.empty:\n            print(result[['staff_name', 'department', 'due_date']].head())\n    else:\n        print(result)\n    \n    # Query 3: Underperformers\n    print(\"\\n[Team Lead] Which staff members are falling behind on mandatory training?\")\n    result = orchestrator.process_query(\"Which staff members are falling behind?\")\n    if isinstance(result, pd.DataFrame):\n        print(f\"\\nFound {len(result)} underperformers\")\n        print(result.head(10))\n    else:\n        print(result)\n    \n    # Query 4: Generate dashboard\n    print(\"\\n[Team Lead] Show me a KPI dashboard\")\n    fig = orchestrator.process_query(\"Show me a KPI dashboard\")\n    if hasattr(fig, 'savefig'):\n        plt.show()\n    \n    # Get audit logs\n    print(\"\\n\" + \"=\" * 60)\n    print(\"AUDIT LOGS\")\n    print(\"=\" * 60)\n    logs = orchestrator.get_all_audit_logs()\n    total_actions = sum(len(v) for v in logs.values())\n    print(f\"Total actions logged: {total_actions}\")\n    \n    print(\"\\nActions per agent:\")\n    for agent_name, agent_logs in logs.items():\n        print(f\"  {agent_name}: {len(agent_logs)} actions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:24.689701Z","iopub.execute_input":"2025-11-23T17:28:24.690063Z","iopub.status.idle":"2025-11-23T17:28:25.464862Z","shell.execute_reply.started":"2025-11-23T17:28:24.690002Z","shell.execute_reply":"2025-11-23T17:28:25.464021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- ADK tool integration: shared orchestrator factory ----\n\nfrom typing import Optional\n\n_GLOBAL_ORCHESTRATOR: Optional[OrchestratorAgent] = None\n\ndef get_orchestrator() -> OrchestratorAgent:\n    \"\"\"\n    Returns a singleton OrchestratorAgent instance that ADK tools can use.\n\n    This function ensures that the agents and orchestrator are initialized\n    exactly once, and then reused across tool calls.\n    \"\"\"\n    global _GLOBAL_ORCHESTRATOR\n    if _GLOBAL_ORCHESTRATOR is None:\n        # paths\n        staff_df = pd.read_csv(\"/kaggle/working/sample_staff.csv\")\n        modules_df = pd.read_csv(\"/kaggle/working/training_modules.csv\")\n        completions_df = pd.read_csv(\"/kaggle/working/completions.csv\")\n\n        _GLOBAL_ORCHESTRATOR = initialize_agents(\n            staff_df=staff_df,\n            modules_df=modules_df,\n            completions_df=completions_df,\n        )\n    return _GLOBAL_ORCHESTRATOR\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.465608Z","iopub.execute_input":"2025-11-23T17:28:25.465904Z","iopub.status.idle":"2025-11-23T17:28:25.471995Z","shell.execute_reply.started":"2025-11-23T17:28:25.465874Z","shell.execute_reply":"2025-11-23T17:28:25.471078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tests ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Tuple\nimport json\n\nclass CPDAgentTester:\n    \"\"\"Comprehensive testing framework for CPD Assistant agents\"\"\"\n    \n    def __init__(self, orchestrator, staff_df, modules_df, completions_df):\n        self.orchestrator = orchestrator\n        self.staff_df = staff_df\n        self.modules_df = modules_df\n        \n        # Ensure date columns are properly formatted\n        self.completions_df = completions_df.copy()\n        self.completions_df['due_date'] = pd.to_datetime(self.completions_df['due_date']).dt.date\n        if 'completion_date' in self.completions_df.columns:\n            self.completions_df['completion_date'] = pd.to_datetime(self.completions_df['completion_date'], errors='coerce').dt.date\n        \n        self.test_results = []\n        \n    def calculate_ground_truth(self):\n        \"\"\"Calculate expected values from raw data\"\"\"\n        # Merge data\n        merged = (\n            self.completions_df\n            .merge(self.staff_df, on=\"staff_id\", how=\"left\")\n            .merge(self.modules_df, on=\"module_id\", how=\"left\")\n        )\n        \n        ground_truth = {\n            \"total_records\": len(merged),\n            \"completed_count\": (merged[\"status\"] == \"Completed\").sum(),\n            \"pending_count\": (merged[\"status\"] == \"Pending\").sum(),\n            \"overdue_count\": (merged[\"status\"] == \"Overdue\").sum(),\n            \"completion_rate\": (merged[\"status\"] == \"Completed\").sum() / len(merged) * 100,\n            \"safeguarding_pending\": len(merged[\n                (merged[\"module_name\"] == \"Safeguarding\") & \n                (merged[\"status\"].isin([\"Pending\", \"Overdue\"]))\n            ]),\n            \"unique_staff\": merged[\"staff_id\"].nunique(),\n            \"unique_modules\": merged[\"module_id\"].nunique(),\n        }\n        \n        # Calculate underperformers (< 70% completion)\n        staff_totals = merged.groupby(\"staff_id\")[\"status\"].count()\n        staff_completed = merged[merged[\"status\"] == \"Completed\"].groupby(\"staff_id\")[\"status\"].count()\n        staff_rates = (staff_completed / staff_totals * 100).fillna(0)\n        ground_truth[\"underperformers_count\"] = (staff_rates < 70).sum()\n        \n        return ground_truth\n    \n    def test_completion_rate_accuracy(self):\n        \"\"\"Test 1: Verify completion rate calculation\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 1: Completion Rate Accuracy\")\n        print(\"=\"*60)\n        \n        # Get ground truth\n        gt = self.calculate_ground_truth()\n        \n        # Get agent result\n        result = self.orchestrator.process_query(\"What's the overall training completion rate?\")\n        \n        # Compare\n        expected_rate = round(gt[\"completion_rate\"], 2)\n        actual_rate = result.get(\"completion_rate\", 0)\n        \n        accuracy = 100 - abs(expected_rate - actual_rate)\n        passed = abs(expected_rate - actual_rate) < 0.1\n        \n        test_result = {\n            \"test_name\": \"Completion Rate\",\n            \"expected\": expected_rate,\n            \"actual\": actual_rate,\n            \"accuracy\": accuracy,\n            \"passed\": passed,\n            \"details\": {\n                \"expected_completed\": gt[\"completed_count\"],\n                \"actual_completed\": result.get(\"completed\", 0),\n                \"expected_total\": gt[\"total_records\"],\n                \"actual_total\": result.get(\"total_training_records\", 0)\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_pending_safeguarding_accuracy(self):\n        \"\"\"Test 2: Verify pending safeguarding training count\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 2: Pending Safeguarding Training Accuracy\")\n        print(\"=\"*60)\n        \n        gt = self.calculate_ground_truth()\n        \n        result = self.orchestrator.process_query(\"How many staff are pending safeguarding training?\")\n        \n        expected_count = gt[\"safeguarding_pending\"]\n        actual_count = len(result) if isinstance(result, pd.DataFrame) else 0\n        \n        accuracy = 100 if expected_count == actual_count else 0\n        passed = expected_count == actual_count\n        \n        test_result = {\n            \"test_name\": \"Pending Safeguarding\",\n            \"expected\": expected_count,\n            \"actual\": actual_count,\n            \"accuracy\": accuracy,\n            \"passed\": passed,\n            \"details\": {\n                \"query_type\": \"DataFrame\" if isinstance(result, pd.DataFrame) else type(result).__name__\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_underperformers_accuracy(self):\n        \"\"\"Test 3: Verify underperformers identification\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 3: Underperformers Identification Accuracy\")\n        print(\"=\"*60)\n        \n        gt = self.calculate_ground_truth()\n        \n        result = self.orchestrator.process_query(\"Which staff members are falling behind?\")\n        \n        expected_count = gt[\"underperformers_count\"]\n        actual_count = len(result) if isinstance(result, pd.DataFrame) else 0\n        \n        accuracy = 100 if expected_count == actual_count else max(0, 100 - abs(expected_count - actual_count) * 10)\n        passed = expected_count == actual_count\n        \n        test_result = {\n            \"test_name\": \"Underperformers\",\n            \"expected\": expected_count,\n            \"actual\": actual_count,\n            \"accuracy\": accuracy,\n            \"passed\": passed,\n            \"details\": {\n                \"threshold\": 70,\n                \"query_type\": \"DataFrame\" if isinstance(result, pd.DataFrame) else type(result).__name__\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_overdue_training_accuracy(self):\n        \"\"\"Test 4: Verify overdue training records\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 4: Overdue Training Records Accuracy\")\n        print(\"=\"*60)\n        \n        gt = self.calculate_ground_truth()\n        \n        result = self.orchestrator.process_query(\"Show me overdue training\")\n        \n        expected_count = gt[\"overdue_count\"]\n        actual_count = len(result) if isinstance(result, pd.DataFrame) else 0\n        \n        # Allow some tolerance for date boundary issues\n        tolerance = 2\n        accuracy = 100 if abs(expected_count - actual_count) <= tolerance else max(0, 100 - abs(expected_count - actual_count) * 5)\n        passed = abs(expected_count - actual_count) <= tolerance\n        \n        test_result = {\n            \"test_name\": \"Overdue Training\",\n            \"expected\": expected_count,\n            \"actual\": actual_count,\n            \"accuracy\": accuracy,\n            \"passed\": passed,\n            \"details\": {\n                \"tolerance\": tolerance,\n                \"difference\": abs(expected_count - actual_count)\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_reminder_generation(self):\n        \"\"\"Test 5: Verify reminder email generation\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 5: Reminder Email Generation\")\n        print(\"=\"*60)\n        \n        # Pick a staff member with pending training\n        pending = self.completions_df[self.completions_df[\"status\"].isin([\"Pending\", \"Overdue\"])]\n        \n        if pending.empty:\n            print(\"âš ï¸  No pending training found for testing reminders\")\n            return None\n        \n        test_staff_id = pending.iloc[0][\"staff_id\"]\n        \n        result = self.orchestrator.process_query(f\"Generate reminder email for staff_id {test_staff_id}\")\n        \n        # Check if result is a string email\n        is_string = isinstance(result, str)\n        contains_staff_name = \"Staff_\" in result if is_string else False\n        contains_modules = any(mod in result for mod in [\"Safeguarding\", \"Data Protection\", \"Fire Safety\"]) if is_string else False\n        \n        passed = is_string and contains_staff_name and (contains_modules or \"No pending\" in result)\n        accuracy = 100 if passed else 50\n        \n        test_result = {\n            \"test_name\": \"Reminder Generation\",\n            \"expected\": \"Email string with staff name and modules\",\n            \"actual\": \"Valid email\" if passed else \"Invalid format\",\n            \"accuracy\": accuracy,\n            \"passed\": passed,\n            \"details\": {\n                \"test_staff_id\": test_staff_id,\n                \"is_string\": is_string,\n                \"contains_staff_name\": contains_staff_name,\n                \"contains_modules\": contains_modules\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_module_statistics(self):\n        \"\"\"Test 6: Verify module-level statistics\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 6: Module Statistics Accuracy\")\n        print(\"=\"*60)\n        \n        # Get module stats from agent\n        module_stats = self.orchestrator.monitoring_agent.get_module_statistics()\n        \n        # Calculate ground truth per module\n        merged = (\n            self.completions_df\n            .merge(self.modules_df, on=\"module_id\", how=\"left\")\n        )\n        \n        expected_modules = set(merged[\"module_name\"].unique())\n        actual_modules = set(module_stats[\"module_name\"].tolist())\n        \n        modules_match = expected_modules == actual_modules\n        accuracy = 100 if modules_match else 75\n        \n        test_result = {\n            \"test_name\": \"Module Statistics\",\n            \"expected\": len(expected_modules),\n            \"actual\": len(actual_modules),\n            \"accuracy\": accuracy,\n            \"passed\": modules_match,\n            \"details\": {\n                \"expected_modules\": sorted(list(expected_modules)),\n                \"actual_modules\": sorted(list(actual_modules))\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def test_audit_logging(self):\n        \"\"\"Test 7: Verify audit log completeness\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST 7: Audit Logging Completeness\")\n        print(\"=\"*60)\n        \n        logs = self.orchestrator.get_all_audit_logs()\n        \n        # Check all agents have logs\n        expected_agents = [\"orchestrator\", \"hr_agent\", \"monitoring_agent\", \"reporting_agent\", \"reminder_agent\"]\n        agents_with_logs = [agent for agent in expected_agents if len(logs.get(agent, [])) > 0]\n        \n        completeness = len(agents_with_logs) / len(expected_agents) * 100\n        passed = completeness >= 80\n        \n        test_result = {\n            \"test_name\": \"Audit Logging\",\n            \"expected\": len(expected_agents),\n            \"actual\": len(agents_with_logs),\n            \"accuracy\": completeness,\n            \"passed\": passed,\n            \"details\": {\n                \"agents_with_logs\": agents_with_logs,\n                \"total_log_entries\": sum(len(v) for v in logs.values())\n            }\n        }\n        \n        self.test_results.append(test_result)\n        self._print_test_result(test_result)\n        return test_result\n    \n    def run_all_tests(self):\n        \"\"\"Run all accuracy tests\"\"\"\n        print(\"\\n\" + \"ğŸ§ª\" + \"=\"*58 + \"ğŸ§ª\")\n        print(\"  CPD ASSISTANT - COMPREHENSIVE ACCURACY TESTING\")\n        print(\"ğŸ§ª\" + \"=\"*58 + \"ğŸ§ª\")\n        \n        # Run all tests\n        self.test_completion_rate_accuracy()\n        self.test_pending_safeguarding_accuracy()\n        self.test_underperformers_accuracy()\n        self.test_overdue_training_accuracy()\n        self.test_reminder_generation()\n        self.test_module_statistics()\n        self.test_audit_logging()\n        \n        # Generate summary\n        self.print_summary()\n        \n        return self.test_results\n    \n    def print_summary(self):\n        \"\"\"Print test summary with overall accuracy\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"ğŸ“Š TEST SUMMARY\")\n        print(\"=\"*60)\n        \n        if not self.test_results:\n            print(\"No tests run yet!\")\n            return\n        \n        total_tests = len(self.test_results)\n        passed_tests = sum(1 for t in self.test_results if t[\"passed\"])\n        overall_accuracy = np.mean([t[\"accuracy\"] for t in self.test_results])\n        \n        print(f\"\\nTotal Tests Run: {total_tests}\")\n        print(f\"Tests Passed: {passed_tests} âœ…\")\n        print(f\"Tests Failed: {total_tests - passed_tests} âŒ\")\n        print(f\"Pass Rate: {passed_tests/total_tests*100:.1f}%\")\n        print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n        \n        # Grade\n        if overall_accuracy >= 95:\n            grade = \"A+ (Excellent)\"\n        elif overall_accuracy >= 90:\n            grade = \"A (Very Good)\"\n        elif overall_accuracy >= 80:\n            grade = \"B (Good)\"\n        elif overall_accuracy >= 70:\n            grade = \"C (Acceptable)\"\n        else:\n            grade = \"D (Needs Improvement)\"\n        \n        print(f\"\\nğŸ¯ Overall Grade: {grade}\")\n        \n        # Detailed results table\n        results_df = pd.DataFrame([\n            {\n                \"Test\": r[\"test_name\"],\n                \"Expected\": r[\"expected\"],\n                \"Actual\": r[\"actual\"],\n                \"Accuracy\": f\"{r['accuracy']:.1f}%\",\n                \"Status\": \"âœ… PASS\" if r[\"passed\"] else \"âŒ FAIL\"\n            }\n            for r in self.test_results\n        ])\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"DETAILED RESULTS:\")\n        print(\"=\"*60)\n        print(results_df.to_string(index=False))\n        \n        return results_df\n    \n    def _print_test_result(self, result):\n        \"\"\"Helper to print individual test results\"\"\"\n        status = \"âœ… PASS\" if result[\"passed\"] else \"âŒ FAIL\"\n        print(f\"\\n{status}\")\n        print(f\"Expected: {result['expected']}\")\n        print(f\"Actual: {result['actual']}\")\n        print(f\"Accuracy: {result['accuracy']:.2f}%\")\n        if result.get(\"details\"):\n            print(f\"Details: {json.dumps(result['details'], indent=2, default=str)}\")\n    \n    def export_results(self, filename=\"/kaggle/working/test_results.json\"):\n        \"\"\"Export test results to JSON file\"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.test_results, f, indent=2, default=str)\n        print(f\"\\nâœ… Test results exported to {filename}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.473074Z","iopub.execute_input":"2025-11-23T17:28:25.473336Z","iopub.status.idle":"2025-11-23T17:28:25.515417Z","shell.execute_reply.started":"2025-11-23T17:28:25.473316Z","shell.execute_reply":"2025-11-23T17:28:25.514312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation ","metadata":{}},{"cell_type":"code","source":"# Usage Example\ndef run_orchestrator_demo():\n    orchestrator = initialize_agents(staff_df, modules_df, completions_df)\n    # Create tester\n    tester = CPDAgentTester(\n        orchestrator=orchestrator,\n        staff_df=staff_df,\n        modules_df=modules_df,\n        completions_df=completions_df\n    )\n    \n    # Run all tests\n    results = tester.run_all_tests()\n    \n    # Export results\n    tester.export_results()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.516407Z","iopub.execute_input":"2025-11-23T17:28:25.516756Z","iopub.status.idle":"2025-11-23T17:28:25.5333Z","shell.execute_reply.started":"2025-11-23T17:28:25.516735Z","shell.execute_reply":"2025-11-23T17:28:25.532443Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#fff3e0; padding:15px; border-left:5px solid #fb8c00; border-radius:6px; font-family:sans-serif;\">\n  <h3>ğŸ› ï¸ Section 2. Problem, Personas & User Stories</h3>\n    \nThis section focuses on Problem, Personas & User Stories by:\n\n 2.1 Detailed Problem Description\n 2.2 User Personas\n 2.3 User Stories & Acceptance Criteria\n 2.4 Non-Functional Requirements","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b></b> \n    \n### âœ… 2.1 Detailed Problem Description \n\n- In UK healthcare and social-care settings, staff must complete a set of mandatory CPD (Continuing Professional Development) modules such as:\n\n- Safeguarding\n\n- Data Protection\n\n- Basic Life Support\n\n- Fire Safety\n\n- Manual Handling\n\n#### Currently, many teams rely on static spreadsheets or rigid LMS dashboards to track this training. \n#### These tools are often:\n\n- Fragmented: Different reports for HR, service leads, and auditors\n\n- Reactive: Issues are spotted only when audits are due or incidents occur\n\n- Hard to query: Team leads canâ€™t easily ask natural questions; they must manually check\n\n- Example: â€œWhich staff are overdue on safeguarding in my team?â€\n\n#### The CPD_Assistant is a multi-agent system that sits on top of a structured CPD dataset (staff, modules, completions) and helps a team lead:\n\n- Monitor who is compliant, pending, or overdue\n\n- Generate KPI summaries and dashboards for their service\n\n- Create actionable reminder messages for staff\n\n- Provide an audit-ready trail of decisions and queries\n\n- The goal is not to replace an LMS, but to orchestrate data and logic into a natural, conversational workflow that supports safer, more proactive compliance management.\n\n### âœ… 2.2 User Personas\n\n##### Persona A â€“ Primary User \n\n- Role: Team Leader\n\n- Goals:\n\n- Ensure all staff are compliant with mandatory CPD modules\n\n- Quickly identify training gaps and take proactive action\n\n- Frustrations:\n\n- Manual tracking is time-consuming and error-prone\n\n- Lack of real-time visibility makes audits stressful\n\n##### Persona B â€“ Secondary User \n\n- Role: HR/Compliance Officer\n\n- Context: Needs consolidated compliance reports across multiple teams to satisfy regulatory audits and inspections.\n\n### âœ… 2.3 User Stories\n\nHere are 5 capstone-friendly user stories:\n\nAs a Team Leader, I want to see a dashboard of staff compliance status so that I can quickly identify who is overdue or pending training.\n\nAs a Team Leader, I want the agent to generate KPI summaries (e.g., % compliance per module) using the structured dataset so that I can report progress to senior management.\n\nAs a Team Leader, I want the agent to send automated reminder messages to staff who are overdue so that I can reduce manual follow-ups and improve compliance rates.\n\nAs a HR/Compliance Officer, I want the agent to produce an audit-ready trail of queries and actions so that I can demonstrate compliance during inspections without scrambling for evidence.\n\nAs a Team Leader, I want to ask natural language queries like â€œWho in my team is overdue on safeguarding?â€ so that I can get instant answers without manually checking spreadsheets.</div>","metadata":{"execution":{"iopub.status.busy":"2025-11-15T19:40:12.922027Z","iopub.execute_input":"2025-11-15T19:40:12.922785Z","iopub.status.idle":"2025-11-15T19:40:12.930548Z","shell.execute_reply.started":"2025-11-15T19:40:12.922751Z","shell.execute_reply":"2025-11-15T19:40:12.929331Z"}}},{"cell_type":"markdown","source":"## 3. Agent Architecture & Design","metadata":{}},{"cell_type":"markdown","source":"\n#### Agent Architecture \n#### Using LangGraph for multi-agent orchestration\n#### Each agent has specific responsibilities (single responsibility principle)\n#### Agents communicate through structured messages\n","metadata":{}},{"cell_type":"markdown","source":"## 3. Agent Architecture & Design\n\n### 3.1 High-Level Flow\n\n1. User provides a request (e.g., â€œHelp me plan â€¦â€, â€œBook â€¦â€, â€œSummarise â€¦â€).\n2. Agent analyses the request and chooses a strategy.\n3. Agent calls tools / MCP servers as needed.\n4. Agent synthesises results and returns a structured, user-friendly response.\n5. (Optional) Agent logs interactions for evaluation and debugging.\n\n### 3.2 Agents & Roles (for multi-agent setups)\n\n- **Controller / Orchestrator Agent:** _Decides which sub-agent to invoke._\n- **Worker Agent(s):**  \n  - Worker 1: _e.g., data fetcher / planner / summariser_  \n  - Worker 2: _e.g., execution agent (runs code, interacts with tools)_  \n\n### 3.3 Design Table (to be filled later)\n\n| Component       | Responsibility                             | Notes / TODO                                      |\n|----------------|---------------------------------------------|---------------------------------------------------|\n| Orchestrator   | Understand user intent, route to sub-agent |                                                   |\n| Tooling Layer  | Wraps tools / MCPs                         | e.g., calendar API, file storage, dummy dataset   |\n| Memory / State | Track past turns / preferences             | Could be in-memory dict or simple vector store    |\n| Evaluator      | Run test scenarios, log outputs            | Manual + automated checks                         |\n","metadata":{}},{"cell_type":"markdown","source":"### 3.1 High-Level Flow\n\n1. User provides a request (e.g., â€œHelp me plan â€¦â€, â€œBook â€¦â€, â€œSummarise â€¦â€).\n2. Agent analyses the request and chooses a strategy.\n3. Agent calls tools / MCP servers as needed.\n4. Agent synthesises results and returns a structured, user-friendly response.\n5. (Optional) Agent logs interactions for evaluation and debugging.","metadata":{}},{"cell_type":"markdown","source":"## 4. Tools & MCP Integration (Design First, Implement Later)\n\n> For now, just define **interfaces** and placeholders for tools.  \n> Later you can wire in real MCP servers or custom tools.\n","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Tool Interface","metadata":{}},{"cell_type":"code","source":"# ==== ADK Tool Wrappers for CPD Assistant ====\n\nfrom typing import Dict, Any, List, Optional\n\nToolResult = Dict[str, Any]\n\n\ndef cpd_get_completion_rate(\n    department: Optional[str] = None,\n) -> ToolResult:\n    \"\"\"\n    Computes the overall mandatory training completion rate.\n\n    Args:\n        department: Optional department name. If provided, the completion rate\n            is computed only for that department. If omitted or None, the rate\n            is computed across all departments.\n\n    Returns:\n        A JSON-serializable dictionary with:\n            - total_training_records (int)\n            - completed (int)\n            - pending (int)\n            - completion_rate (float, percent)\n            - department (str)\n    \"\"\"\n    orchestrator = get_orchestrator()\n    monitoring = orchestrator.monitoring_agent\n    metrics = monitoring.calculate_completion_rate(department=department)\n    # Already JSON-safe\n    return metrics\n\n\ndef cpd_get_pending_training(\n    module_name: Optional[str] = None,\n) -> ToolResult:\n    \"\"\"\n    Returns all pending or overdue training records.\n\n    Args:\n        module_name: Optional module name filter (e.g., \\\"Safeguarding\\\").\n            If provided, only pending/overdue records for that module are\n            returned. Otherwise, all modules are included.\n\n    Returns:\n        A dictionary with:\n            - module_filter (str)\n            - count (int)\n            - records (list[dict]) where each record includes:\n                staff_id, staff_name, department, module_name, status, due_date\n    \"\"\"\n    orchestrator = get_orchestrator()\n    hr_agent = orchestrator.hr_agent\n\n    df = hr_agent.get_pending_training(module_name=module_name)\n    if df.empty:\n        return {\n            \"module_filter\": module_name or \"all\",\n            \"count\": 0,\n            \"records\": [],\n        }\n\n    # Convert to JSON-safe records\n    subset_cols = [\n        \"staff_id\",\n        \"staff_name\",\n        \"department\",\n        \"module_name\",\n        \"status\",\n        \"due_date\",\n    ]\n    existing_cols = [c for c in subset_cols if c in df.columns]\n    records: List[Dict[str, Any]] = df[existing_cols].copy()\n\n    # Ensure dates are strings\n    if \"due_date\" in records.columns:\n        records[\"due_date\"] = records[\"due_date\"].astype(str)\n\n    return {\n        \"module_filter\": module_name or \"all\",\n        \"count\": int(len(records)),\n        \"records\": records.to_dict(orient=\"records\"),\n    }\n\n\ndef cpd_get_underperformers(\n    completion_threshold: float = 70.0,\n    limit: int = 20,\n) -> ToolResult:\n    \"\"\"\n    Identifies staff members whose overall completion rate is below a threshold.\n\n    Args:\n        completion_threshold: Minimum acceptable completion rate (0â€“100).\n            Staff below this threshold are considered underperformers.\n        limit: Maximum number of staff to return, sorted by completion_rate\n            ascending (worst first).\n\n    Returns:\n        A dictionary with:\n            - threshold (float)\n            - count (int)\n            - underperformers (list[dict]) where each record includes:\n                staff_id, staff_name, completion_rate\n    \"\"\"\n    orchestrator = get_orchestrator()\n    monitoring = orchestrator.monitoring_agent\n\n    df = monitoring.identify_underperformers(threshold=completion_threshold)\n    if df.empty:\n        return {\n            \"threshold\": completion_threshold,\n            \"count\": 0,\n            \"underperformers\": [],\n        }\n\n    df = df.sort_values(\"completion_rate\").head(limit)\n    records = df[[\"staff_id\", \"staff_name\", \"completion_rate\"]].copy()\n    return {\n        \"threshold\": float(completion_threshold),\n        \"count\": int(len(records)),\n        \"underperformers\": records.to_dict(orient=\"records\"),\n    }\n\n\ndef cpd_get_overdue_training() -> ToolResult:\n    \"\"\"\n    Returns all records where mandatory training is overdue.\n\n    Overdue is defined as either:\n      - status == \\\"Overdue\\\", or\n      - status == \\\"Pending\\\" and due_date is earlier than today.\n\n    Returns:\n        A dictionary with:\n            - count (int)\n            - records (list[dict]) where each record includes:\n                staff_id, staff_name, department, module_name, status, due_date\n    \"\"\"\n    orchestrator = get_orchestrator()\n    hr_agent = orchestrator.hr_agent\n\n    df = hr_agent.get_overdue_training()\n    if df.empty:\n        return {\"count\": 0, \"records\": []}\n\n    subset_cols = [\n        \"staff_id\",\n        \"staff_name\",\n        \"department\",\n        \"module_name\",\n        \"status\",\n        \"due_date\",\n    ]\n    existing_cols = [c for c in subset_cols if c in df.columns]\n    records = df[existing_cols].copy()\n    if \"due_date\" in records.columns:\n        records[\"due_date\"] = records[\"due_date\"].astype(str)\n\n    return {\n        \"count\": int(len(records)),\n        \"records\": records.to_dict(orient=\"records\"),\n    }\n\n\ndef cpd_generate_reminder_email(\n    staff_id: int,\n) -> ToolResult:\n    \"\"\"\n    Generates a tailored reminder email for a specific staff member.\n\n    Args:\n        staff_id: Unique identifier for the staff member.\n\n    Returns:\n        A dictionary with:\n            - staff_id (int)\n            - email_body (str)\n    \"\"\"\n    orchestrator = get_orchestrator()\n    reminder = orchestrator.reminder_agent\n\n    email_text = reminder.generate_reminder_email(staff_id=staff_id)\n    return {\n        \"staff_id\": int(staff_id),\n        \"email_body\": email_text,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.534182Z","iopub.execute_input":"2025-11-23T17:28:25.534486Z","iopub.status.idle":"2025-11-23T17:28:25.551183Z","shell.execute_reply.started":"2025-11-23T17:28:25.534465Z","shell.execute_reply":"2025-11-23T17:28:25.550101Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.2 Planned Tools / MCP Servers\n\n| Tool / MCP          | Type         | Purpose / Capability                         | Status |\n|---------------------|-------------|----------------------------------------------|--------|\n| `example_tool`      | local stub  | Placeholder, used in early agent loop demos | âœ… demo |\n| `TODO_tool_1`       | MCP / API   | _e.g., calendar, file store, dataset search_ | ğŸ•’ plan |\n| `TODO_tool_2`       | MCP / local | _e.g., notebook runner, summariser, RAG_     | ğŸ•’ plan |\n","metadata":{}},{"cell_type":"markdown","source":"## 5. Core Agent Loop \n\n> This section will evolve as your topic crystallises.  \n> Start with a simple â€œthink â†’ maybe call tool â†’ respondâ€ loop.\n","metadata":{}},{"cell_type":"code","source":"# ==== ADK LlmAgent that uses CPD tools ====\nMODEL_ID = \"gemini-2.0-flash\"\n\ngemini_model = Gemini(model=MODEL_ID)\n\ncpd_llm_agent = LlmAgent(\n    model=gemini_model,\n    name=\"cpd_assistant\",\n    instruction=(\n        \"You are CPD_Assistant, a multi-agent system that helps healthcare \"\n        \"team leads monitor mandatory training compliance. \"\n        \"Use the available tools to answer questions with accurate numbers \"\n        \"and clear explanations. When appropriate, call multiple tools and \"\n        \"summarise the results in plain English for non-technical users.\"\n    ),\n    tools=[\n        cpd_get_completion_rate,\n        cpd_get_pending_training,\n        cpd_get_underperformers,\n        cpd_get_overdue_training,\n        cpd_generate_reminder_email,\n    ],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.552306Z","iopub.execute_input":"2025-11-23T17:28:25.552602Z","iopub.status.idle":"2025-11-23T17:28:25.569575Z","shell.execute_reply.started":"2025-11-23T17:28:25.552572Z","shell.execute_reply":"2025-11-23T17:28:25.568636Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1 Multi-turn Demo Skeleton ","metadata":{}},{"cell_type":"code","source":"import asyncio\n\nasync def ask_cpd_agent(message: str, user_id: str = \"demo_user\", session_id: str = \"cpd_demo\"):\n    print(f\"\\nUser > {message}\")\n    response = await runner.run_debug(\n        [message],\n        user_id=user_id,\n        session_id=session_id,\n        verbose=True,\n    )\n    # You can pretty-print or just return it\n    return response\n\n# Example calls (uncomment to try in Kaggle):\n#(ask_cpd_agent(\"What is the overall training completion rate?\"))\n#(ask_cpd_agent(\"Which staff are underperforming below 70% completion?\"))\n# asyncio.run(ask_cpd_agent(\"Please generate a reminder email for staff_id: 101\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:54:31.298016Z","iopub.execute_input":"2025-11-23T17:54:31.298318Z","iopub.status.idle":"2025-11-23T17:54:31.306268Z","shell.execute_reply.started":"2025-11-23T17:54:31.298296Z","shell.execute_reply":"2025-11-23T17:54:31.305285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pprint import pprint\n\nresp = await ask_cpd_agent(\"What is the overall training completion rate?\")\npprint(resp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:57:16.829824Z","iopub.execute_input":"2025-11-23T17:57:16.830797Z","iopub.status.idle":"2025-11-23T17:57:16.843538Z","shell.execute_reply.started":"2025-11-23T17:57:16.830763Z","shell.execute_reply":"2025-11-23T17:57:16.842349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Evaluation & Metrics","metadata":{}},{"cell_type":"markdown","source":"\n### 6.1 What Does â€œGoodâ€ Look Like?\n\n- **Task success:**  \n  - Definition: _e.g., agent produces a correct schedule / summary / plan etc._  \n  - Metric: _% of test cases where output is acceptable._\n\n- **User experience:**  \n  - Definition: _clarity, helpfulness, structure of responses_  \n  - Metric: _manual rating 1â€“5 for each scenario._\n\n- **Reliability & robustness:**  \n  - Definition: _agent handles edge cases / missing info gracefully._  \n  - Metric: _% of scenarios where agent fails safely (no crash, clear message)._\n\n### 6.2 Test Scenarios\n\nDescribe at least 5â€“10 example prompts that your agent should handle well.\n","metadata":{}},{"cell_type":"markdown","source":"## 7. Safety, Limitations & Future Work","metadata":{}},{"cell_type":"markdown","source":"\n### 7.1 Safety & Guardrails\n\n- **Scope limitations:**  \n  - The agent should NOT:  \n    - _e.g., handle medical/financial/legal advice beyond simple templates_  \n  - It SHOULD:  \n    - _e.g., clearly state limitations when unsure._\n\n- **Error handling:**  \n  - How does the agent react when tools fail?  \n  - How are timeouts / missing data handled?\n\n### 7.2 Known Limitations\n\n- _E.g., hallucinations, limited evaluation, small number of scenarios._\n\n### 7.3 Future Work\n\n- Add more tools / MCPs (e.g., real calendar / file systems / dataset integration).\n- Introduce vector store + RAG for domain documents.\n- Improve evaluation (automatic checks + human feedback).\n- Hardening prompts and system instructions.\n","metadata":{}},{"cell_type":"markdown","source":"## 8. Appendix\n\n### 8.1 Final Prompt Templates\n\n_TODO: Paste final system prompt(s), tool prompts, few-shot examples, etc._\n\n### 8.2 Environment Info\n\nBelow cell captures library versions and basic environment info.\n","metadata":{}},{"cell_type":"code","source":"import sys\nimport platform\n\nprint(\"Python version:\", sys.version)\nprint(\"Platform:\", platform.platform())\nprint(\"\\nInstalled key packages (if any):\")\n# !pip list | head -n 20  # Uncomment in Kaggle to inspect\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:28:25.590326Z","iopub.execute_input":"2025-11-23T17:28:25.590618Z","iopub.status.idle":"2025-11-23T17:28:25.60622Z","shell.execute_reply.started":"2025-11-23T17:28:25.590587Z","shell.execute_reply":"2025-11-23T17:28:25.605318Z"}},"outputs":[],"execution_count":null}]}